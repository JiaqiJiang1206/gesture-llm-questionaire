<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<title>Document</title>
	</head>
	<body>
		<div class="wrapper">
			<header>
				<h1>Web dictaphone</h1>
			</header>

			<section class="main-controls">
				<canvas class="visualizer" height="60px"></canvas>
				<div id="buttons">
					<button class="record">Record</button>
					<button class="stop">Stop</button>
				</div>
                <video autoplay></video>
			</section>

			<section class="sound-clips"></section>
		</div>
		<label for="toggle">❔</label>
		<input type="checkbox" id="toggle" />
		<aside>
			<h2>Information</h2>

			<p>
				Web dictaphone is built using
				<a
					href="https://developer.mozilla.org/en-US/docs/Web/API/Navigator.getUserMedia"
					>getUserMedia</a
				>
				and the
				<a
					href="https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder_API"
					>MediaRecorder API</a
				>, which provides an easier way to capture Media streams.
			</p>

			<p>
				Icon courtesy of
				<a href="http://findicons.com/search/microphone">Find Icons</a>. Thanks
				to <a href="http://soledadpenades.com/">Sole</a> for the Oscilloscope
				code!
			</p>
		</aside>
		<script>
			// set up basic variables for app

			const record = document.querySelector(".record");
			const stop = document.querySelector(".stop");
			const soundClips = document.querySelector(".sound-clips");
			const canvas = document.querySelector(".visualizer");
			const mainSection = document.querySelector(".main-controls");
            const video = document.querySelector("video");

			// disable stop button while not recording

			stop.disabled = true;

			// visualiser setup - create web audio api context and canvas

			let audioCtx;
			const canvasCtx = canvas.getContext("2d");

			// main block for doing the audio recording
			if (navigator.mediaDevices.getUserMedia) {
				console.log("getUserMedia supported.");

                // 音频视频约束
				const constraints = {
					audio: true,
					video: true,
				};
				let chunks = [];

                // getUserMedia 成功的回调函数
				let onSuccess = function (stream) {
					const mediaRecorder = new MediaRecorder(stream);

					visualize(stream);
                    video.srcObject = stream;

					record.onclick = function () {
						mediaRecorder.start();
						console.log(mediaRecorder.state);
						console.log("recorder started");
						record.style.background = "red";

						stop.disabled = false;
						record.disabled = true;
					};

					stop.onclick = function () {
						mediaRecorder.stop();
						console.log(mediaRecorder.state);
						console.log("recorder stopped");
						record.style.background = "";
						record.style.color = "";
						// mediaRecorder.requestData();

						stop.disabled = true;
						record.disabled = false;

                        // stop all tracks
                        stream.getTracks().forEach(track => track.stop());
					};

					mediaRecorder.onstop = function (e) {
						console.log("data available after MediaRecorder.stop() called.");

						const clipName = prompt(
							"Enter a name for your sound clip?",
							"My unnamed clip"
						);

						const clipContainer = document.createElement("article");
						const clipLabel = document.createElement("p");
						const audio = document.createElement("audio");
						const deleteButton = document.createElement("button");

						clipContainer.classList.add("clip");
						audio.setAttribute("controls", "");
						deleteButton.textContent = "Delete";
						deleteButton.className = "delete";

						if (clipName === null) {
							clipLabel.textContent = "My unnamed clip";
						} else {
							clipLabel.textContent = clipName;
						}

						clipContainer.appendChild(audio);
						clipContainer.appendChild(clipLabel);
						clipContainer.appendChild(deleteButton);
						soundClips.appendChild(clipContainer);

						audio.controls = true;
						const blob = new Blob(chunks, { type: "audio/ogg; codecs=opus" });
						chunks = [];
						const audioURL = window.URL.createObjectURL(blob);
						audio.src = audioURL;
						console.log("recorder stopped");

						deleteButton.onclick = function (e) {
							let evtTgt = e.target;
							evtTgt.parentNode.parentNode.removeChild(evtTgt.parentNode);
						};

						clipLabel.onclick = function () {
							const existingName = clipLabel.textContent;
							const newClipName = prompt(
								"Enter a new name for your sound clip?"
							);
							if (newClipName === null) {
								clipLabel.textContent = existingName;
							} else {
								clipLabel.textContent = newClipName;
							}
						};
					};

					mediaRecorder.ondataavailable = function (e) {
						chunks.push(e.data);
					};
				};

                // getUserMedia 失败的回调函数
				let onError = function (err) {
					console.log("The following error occured: " + err);
				};

                // 获取音频视频流
				navigator.mediaDevices
					.getUserMedia(constraints)
					.then(onSuccess, onError);
			} else {
				console.log("getUserMedia not supported on your browser!");
			}

            // 可视化音频
			function visualize(stream) {
				if (!audioCtx) {
					audioCtx = new AudioContext();
				}

				const source = audioCtx.createMediaStreamSource(stream);

				const analyser = audioCtx.createAnalyser();
				analyser.fftSize = 2048;
				const bufferLength = analyser.frequencyBinCount;
				const dataArray = new Uint8Array(bufferLength);

				source.connect(analyser);
				//analyser.connect(audioCtx.destination);

				draw();

				function draw() {
					const WIDTH = canvas.width;
					const HEIGHT = canvas.height;

					requestAnimationFrame(draw);

					analyser.getByteTimeDomainData(dataArray);

					canvasCtx.fillStyle = "rgb(200, 200, 200)";
					canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

					canvasCtx.lineWidth = 2;
					canvasCtx.strokeStyle = "rgb(0, 0, 0)";

					canvasCtx.beginPath();

					let sliceWidth = (WIDTH * 1.0) / bufferLength;
					let x = 0;

					for (let i = 0; i < bufferLength; i++) {
						let v = dataArray[i] / 128.0;
						let y = (v * HEIGHT) / 2;

						if (i === 0) {
							canvasCtx.moveTo(x, y);
						} else {
							canvasCtx.lineTo(x, y);
						}

						x += sliceWidth;
					}

					canvasCtx.lineTo(canvas.width, canvas.height / 2);
					canvasCtx.stroke();
				}
			}

            // 设置 canvas 宽度
			window.onresize = function () {
				canvas.width = mainSection.offsetWidth;
			};

            // 初始化 canvas 宽度
			window.onresize();
		</script>
	</body>
</html>
